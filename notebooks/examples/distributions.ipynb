{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excited-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from pvi.distributions.base import ExponentialFamilyDistribution\n",
    "from pvi.distributions.base import ExponentialFamilyFactor\n",
    "from pvi.distributions.exponential_family_distributions import *\n",
    "from pvi.distributions.exponential_family_factors import *\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-playback",
   "metadata": {},
   "source": [
    "# Test t-factors\n",
    "\n",
    "## Mean-field Gaussian Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "D = 2\n",
    "\n",
    "mean = torch.zeros(size=(D,))\n",
    "prec = torch.ones(size=(D,))\n",
    "natural_parameters = {\"np1\" : mean / prec,\n",
    "                      \"np2\" : -0.5 * prec}\n",
    "\n",
    "thetas = torch.ones(size=(N, D))\n",
    "\n",
    "mean_field_gaussian = MeanFieldGaussianFactor(natural_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "returning-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_field_gaussian(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-percentage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1921e-07, -1.1921e-07])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Normal' object has no attribute 'nat_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dist2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mnormal\u001b[38;5;241m.\u001b[39mNormal(loc\u001b[38;5;241m=\u001b[39mmean, scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m prec) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (dist1\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m dist2\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m prec))\n\u001b[0;32m----> 4\u001b[0m mean_field_gaussian\u001b[38;5;241m.\u001b[39mcompute_refined_factor(dist1, dist2)\u001b[38;5;241m.\u001b[39mnatural_parameters\n",
      "File \u001b[0;32m~/Desktop/PVI-main/pvi/distributions/base.py:49\u001b[0m, in \u001b[0;36mExponentialFamilyFactor.compute_refined_factor\u001b[0;34m(self, q1, q2, damping, valid_dist, update_log_coeff)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mComputes the log-coefficient and natural parameters of the\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mapproximating likelihood term **t** given by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mcoefficient of t_.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Convert distributions to log-coefficients and natural parameters\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m np1 \u001b[38;5;241m=\u001b[39m q1\u001b[38;5;241m.\u001b[39mnat_params\n\u001b[1;32m     50\u001b[0m np2 \u001b[38;5;241m=\u001b[39m q2\u001b[38;5;241m.\u001b[39mnat_params\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Compute natural parameters of the new t-factor (detach gradients)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Normal' object has no attribute 'nat_params'"
     ]
    }
   ],
   "source": [
    "dist1 = torch.distributions.normal.Normal(loc=mean, scale=prec ** -0.5)\n",
    "dist2 = torch.distributions.normal.Normal(loc=mean, scale=(2. * prec) ** -0.5)\n",
    "print(0.5 * (dist1.scale ** -2 - dist2.scale ** -2 + prec))\n",
    "mean_field_gaussian.compute_refined_factor(dist1, dist2).natural_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-surprise",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "successful-moses",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExponentialFamilyFactor.__init__() got an unexpected keyword argument 'natural_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#torch.solve(mean[:, None], prec)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m thetas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(size\u001b[38;5;241m=\u001b[39m(N, D))\n\u001b[0;32m---> 14\u001b[0m multivariate_gaussian \u001b[38;5;241m=\u001b[39m MultivariateGaussianFactor(natural_parameters\u001b[38;5;241m=\u001b[39mnatural_parameters)\n",
      "\u001b[0;31mTypeError\u001b[0m: ExponentialFamilyFactor.__init__() got an unexpected keyword argument 'natural_parameters'"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "D = 2\n",
    "\n",
    "log_coefficient = 0.\n",
    "mean = torch.zeros(size=(D,))\n",
    "prec = torch.eye(D)\n",
    "#prev with .solution[:, 0],\n",
    "natural_parameters = {\"np1\" : torch.linalg.solve(prec, mean[:, None])[:, 0],\n",
    "                      \"np2\" : -0.5 * prec}\n",
    "\n",
    "#torch.solve(mean[:, None], prec)\n",
    "thetas = torch.ones(size=(N, D))\n",
    "\n",
    "multivariate_gaussian = MultivariateGaussianFactor(natural_parameters=natural_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_gaussian(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "D = 2\n",
    "\n",
    "mean = torch.zeros(size=(D,))\n",
    "L = torch.tensor([[1., 0.],\n",
    "                  [0., 1.]])\n",
    "prec = torch.mm(L, L.T)\n",
    "natural_parameters = {\"np1\" : torch.solve(mean[:, None], prec).solution[:, 0],\n",
    "                      \"np2\" : -0.5 * prec}\n",
    "\n",
    "thetas = torch.ones(size=(N, D))\n",
    "\n",
    "multivariate_gaussian = MultivariateGaussianFactor(natural_parameters=natural_parameters)\n",
    "\n",
    "multivariate_gaussian.distribution_from_np(multivariate_gaussian.natural_parameters).scale_tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix=torch.inverse(prec))\n",
    "dist2 = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix=torch.inverse(2 * prec))\n",
    "print(-0.5 * (torch.inverse(dist1.covariance_matrix) - torch.inverse(dist2.covariance_matrix) + prec))\n",
    "multivariate_gaussian.compute_refined_factor(dist1, dist2).natural_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-manchester",
   "metadata": {},
   "source": [
    "# Test distribution base classes\n",
    "\n",
    "## Mean Field Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "D = 2\n",
    "\n",
    "mean = torch.zeros(size=(D,))\n",
    "scale = torch.ones(size=(D,))\n",
    "\n",
    "sp = {\n",
    "    \"sp1\" : mean,\n",
    "    \"sp2\" : scale\n",
    "    \n",
    "}\n",
    "\n",
    "mfgd = MeanFieldGaussianDistribution(std_params=sp,\n",
    "                                     nat_params=None,\n",
    "                                     is_trainable=True)\n",
    "\n",
    "mfgd.rsample().sum().backward()\n",
    "mfgd._unc_params[\"up2\"].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-today",
   "metadata": {},
   "source": [
    "# Multivariate Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guilty-double",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m cov \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(D)\n\u001b[1;32m      7\u001b[0m sp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp1\u001b[39m\u001b[38;5;124m\"\u001b[39m : mean,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp2\u001b[39m\u001b[38;5;124m\"\u001b[39m : cov\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m mvgd \u001b[38;5;241m=\u001b[39m MultivariateGaussianDistribution(std_params\u001b[38;5;241m=\u001b[39msp,\n\u001b[1;32m     14\u001b[0m                                         nat_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m                                         is_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m mvgd\u001b[38;5;241m.\u001b[39mrsample()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/PVI-main/pvi/distributions/base.py:176\u001b[0m, in \u001b[0;36mExponentialFamilyDistribution.__init__\u001b[0;34m(self, std_params, nat_params, is_trainable)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Initialise standard and natural parameters.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd_params \u001b[38;5;241m=\u001b[39m std_params\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nat_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_trainable:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1754\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     buffers[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1754\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(name, value)\n",
      "File \u001b[0;32m~/Desktop/PVI-main/pvi/distributions/base.py:229\u001b[0m, in \u001b[0;36mExponentialFamilyDistribution.std_params\u001b[0;34m(self, std_params)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_params()\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_trainable:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unc_params \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameterDict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unc_from_std(std_params))\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_std_params \u001b[38;5;241m=\u001b[39m std_params\n",
      "File \u001b[0;32m~/Desktop/PVI-main/pvi/distributions/exponential_family_distributions.py:151\u001b[0m, in \u001b[0;36mMultivariateGaussianDistribution._unc_from_std\u001b[0;34m(std_params)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unc_from_std\u001b[39m(std_params):\n\u001b[0;32m--> 151\u001b[0m     loc \u001b[38;5;241m=\u001b[39m std_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    152\u001b[0m     cov \u001b[38;5;241m=\u001b[39m std_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# torch.cholesky is deprecated use torch.linalg.cholesky\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loc'"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "D = 2\n",
    "\n",
    "mean = torch.zeros(size=(D,))\n",
    "cov = torch.eye(D)\n",
    "\n",
    "sp = {\n",
    "    \"sp1\" : mean,\n",
    "    \"sp2\" : cov\n",
    "    \n",
    "}\n",
    "\n",
    "mvgd = MultivariateGaussianDistribution(std_params=sp,\n",
    "                                        nat_params=None,\n",
    "                                        is_trainable=True)\n",
    "\n",
    "mvgd.rsample().sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(size=(D,))\n",
    "cov = torch.eye(D)\n",
    "\n",
    "d1 = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "d2 = torch.distributions.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "\n",
    "torch.distributions.kl_divergence(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.Dirichlet(torch.tensor([0.5, 1e-6]))._natural_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-cutting",
   "metadata": {},
   "source": [
    "## Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compressed-accused",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class DirichletDistribution with abstract method log_a",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m conc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(size\u001b[38;5;241m=\u001b[39m(D,))\u001b[38;5;241m.\u001b[39muniform_()\n\u001b[1;32m      5\u001b[0m sp \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp1\u001b[39m\u001b[38;5;124m\"\u001b[39m : conc}\n\u001b[0;32m----> 7\u001b[0m dird \u001b[38;5;241m=\u001b[39m DirichletDistribution(std_params\u001b[38;5;241m=\u001b[39msp,\n\u001b[1;32m      8\u001b[0m                              nat_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                              is_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m dird\u001b[38;5;241m.\u001b[39mkl_divergence(dird)\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class DirichletDistribution with abstract method log_a"
     ]
    }
   ],
   "source": [
    "D = 4\n",
    "\n",
    "conc = torch.zeros(size=(D,)).uniform_()\n",
    "\n",
    "sp = {\"sp1\" : conc}\n",
    "\n",
    "dird = DirichletDistribution(std_params=sp,\n",
    "                             nat_params=None,\n",
    "                             is_trainable=False)\n",
    "\n",
    "dird.kl_divergence(dird)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-homework",
   "metadata": {},
   "source": [
    "# Multinomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-german",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class MultinomialDistribution with abstract method log_a",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m p \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m/\u001b[39m p\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      6\u001b[0m sp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp1\u001b[39m\u001b[38;5;124m\"\u001b[39m : N,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp2\u001b[39m\u001b[38;5;124m\"\u001b[39m : p\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m muld \u001b[38;5;241m=\u001b[39m MultinomialDistribution(std_params\u001b[38;5;241m=\u001b[39msp,\n\u001b[1;32m     12\u001b[0m                                nat_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                is_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m muld\u001b[38;5;241m.\u001b[39msample()\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class MultinomialDistribution with abstract method log_a"
     ]
    }
   ],
   "source": [
    "D = 10\n",
    "\n",
    "p = torch.zeros(size=(D,)).uniform_()\n",
    "p = p / p.sum()\n",
    "\n",
    "sp = {\n",
    "    \"sp1\" : N,\n",
    "    \"sp2\" : p\n",
    "}\n",
    "\n",
    "muld = MultinomialDistribution(std_params=sp,\n",
    "                               nat_params=None,\n",
    "                               is_trainable=False)\n",
    "\n",
    "muld.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7f192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c902d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
